# Overview
The supported types of fast-customization-on-task are listed below:

- classification
- detection
- segmentation

The dependency is

- torchvision

Now we introduce each type of task by examples.

# Classification
## 1. Format of Configuration File
| **Name**   | **Type** | **Required** | **Description** | **Remark** |
|------------|----------|--------------|-----------------|------------|
| train_data |          | True         |                 | -          |
| get_model  |          | True         |                 | -          |
| test_data  |          | False        |                 |            |
| val_data   |          | False        |                 |            |


**Example:**
```python
import os
import torchvision
import flgo.benchmark

transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))])
root = os.path.join(flgo.benchmark.path,'RAW_DATA', 'SVHN') # 可以为任意存放原始数据的绝对路径
train_data = torchvision.datasets.SVHN(root=root,transform=transform, download=True, split='train')
test_data = torchvision.datasets.SVHN(root=root, transform=transform, download=True, split='test')

class CNN(torch.nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.embedder = torch.nn.Sequential(
            torch.nn.Conv2d(3, 64, 5),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2),
            torch.nn.Conv2d(64, 64, 5),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2),
            torch.nn.Flatten(1),
            torch.nn.Linear(1600, 384),
            torch.nn.ReLU(),
            torch.nn.Linear(384, 192),
            torch.nn.ReLU(),
        )
        self.fc = torch.nn.Linear(192, 10)

    def forward(self, x):
        x = self.embedder(x)
        return self.fc(x)

def get_model():
    return CNN()
```
## 2. Construction
```python
import flgo

# create svhn_classification
bmk = flgo.gen_benchmark_from_file(
    benchmark='svhn_classification',
    config_file='./config_svhn.py',
    target_path='.',
    data_type='cv',
    task_type='classification',
)

# Generate IID federated task
task = './test_svhn'                # task name
task_config = {
    'benchmark': bmk,
    'partitioner':{
        'name':'IIDPartitioner'
    }
}                                   # task configuration
flgo.gen_task(task_config, task)    # generate task

# run fedavg
import flgo.algorithm.fedavg as fedavg
runner = flgo.init(task, fedavg)    # init fedavg runner
runner.run()                        # run
```
# Detection
## 1. Format of Configuration File
| **Name**   | **Type** | **Required** | **Description** | **Remark** |
|------------|----------|--------------|-----------------|------------|
| train_data |          | True         |                 | -          |
| get_model  |          | True         |                 | -          |
| test_data  |          | False        |                 |            |
| val_data   |          | False        |                 |            |

**Example:**
```python
import torch
import torchvision.models
import torchvision.transforms as T
import flgo.benchmark
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import torchvision.datasets
import os
# 0. preprocess VOC
CLASSES = (
    '__background__',
    "aeroplane",
    "bicycle",
    "bird",
    "boat",
    "bottle",
    "bus",
    "car",
    "cat",
    "chair",
    "cow",
    "diningtable",
    "dog",
    "horse",
    "motorbike",
    "person",
    "pottedplant",
    "sheep",
    "sofa",
    "train",
    "tvmonitor",
    )
CLASSES_MAP = {name:idx for idx, name in enumerate(CLASSES)}
def voc_target_transform(y):
    objects = y['annotation']['object']
    boxes = [torch.FloatTensor([int(v) for v in obj['bndbox'].values()]) for obj in objects]
    labels = [torch.LongTensor(torch.LongTensor([CLASSES_MAP[obj['name'].lower()]])) for obj in objects]
    return {'boxes': torch.stack(boxes), 'labels':torch.cat(labels)}
transform = T.Compose([T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
root = os.path.join(flgo.benchmark.path, 'RAW_DATA', 'VOC')

# 1. define train_data and test_data
train_data = torchvision.datasets.VOCDetection(root=root, download=True, image_set='trainval', year='2007', transform=transform, target_transform=voc_target_transform)
test_data = torchvision.datasets.VOCDetection(root=root, download=True, image_set='test', year='2007', transform=transform, target_transform=voc_target_transform)
train_data.num_classes = len(CLASSES)
test_data.num_classes = len(CLASSES)

# 2. define get_model()
def get_model():
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.COCO_V1)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, len(CLASSES))
    return model
```
## 2. Construction
```python
import flgo

# create voc_detection
bmk = flgo.gen_benchmark_from_file(
    benchmark='voc_detection',
    config_file='./config_voc.py',
    target_path='.',
    data_type='cv',
    task_type='detection'
)

# generate federated task
task = './my_IID_voc'
task_config = {
    'benchmark':bmk,
}
flgo.gen_task(task_config, task_path=task)

# run fedavg
import flgo.algorithm.fedavg as fedavg
runner = flgo.init(task, fedavg, {'gpu':[0,],'log_file':True, 'learning_rate':0.0001,'num_epochs':1, 'batch_size':2, 'num_rounds':100, 'proportion':1.0, 'test_batch_size':2, 'train_holdout':0,'eval_interval':1,})
runner.run()
```

# Segmentation
## 1. Format of Configuration File
| **Name**   | **Type** | **Required** | **Description** | **Remark** |
|------------|----------|--------------|-----------------|------------|
| train_data |          | True         |                 | -          |
| get_model  |          | True         |                 | -          |
| test_data  |          | False        |                 |            |
| val_data   |          | False        |                 |            |


**Example:**
```python
import os
import torchvision
import torch
import torchvision.transforms as T

transform = T.Compose([
    T.ToTensor(),
    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
target_transform = T.Compose([
    T.PILToTensor(),
    T.Lambda(lambda x: (x-1).squeeze().type(torch.LongTensor))
])
path = os.path.join(os.path.dirname(os.path.abspath(__file__)))
# define train_data
train_data = torchvision.datasets.OxfordIIITPet(root=path, split='trainval', download=True, target_types='segmentation', transform=transform, target_transform=target_transform)
# define test_data
test_data = torchvision.datasets.OxfordIIITPet(root=path, split='test', download=True, target_types='segmentation', transform=transform, target_transform=target_transform)
# set num_classes=2 (i.e. classes in dataset) + 1 (i.e. background)
train_data.num_classes = 3
test_data.num_classes = 3

def get_model():
    model = torchvision.models.segmentation.fcn_resnet50(num_classes=3)
    return model
```
## 2. Construction
```python
import flgo

# create oxfordiiitpet_segmentation
bmk = flgo.gen_benchmark_from_file(
    benchmark='oxfordiiitpet_segmentation',
    config_file='./config_oxford.py',
    target_path='.',
    data_type='cv',
    task_type='segmentation'
)

# generate federated task
task = './my_IID_oxford'
task_config = {
    'benchmark':bmk,
}
flgo.gen_task(task_config, task_path=task)

# run fedavg
import flgo.algorithm.fedavg as fedavg
runner = flgo.init(task, fedavg, {'gpu':0,'log_file':True, 'learning_rate':0.01, 'num_steps':1, 'batch_size':2, 'num_rounds':1000, 'test_batch_size':8, 'train_holdout':0})
runner.run()
```